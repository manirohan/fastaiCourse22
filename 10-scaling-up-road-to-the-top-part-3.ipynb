{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51f17fe5",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "# install fastkaggle if not available\n",
    "try: import fastkaggle\n",
    "except ModuleNotFoundError:\n",
    "    !pip install -Uq fastkaggle\n",
    "\n",
    "from fastkaggle import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394d59b3",
   "metadata": {},
   "source": [
    "This is part 3 of the [Road to the Top](https://www.kaggle.com/code/jhoward/first-steps-road-to-the-top-part-1) series, in which I show the process I used to tackle the [Paddy Doctor](https://www.kaggle.com/competitions/paddy-disease-classification) competition, leading to four 1st place submissions. The previous notebook is available here: [part 2](https://www.kaggle.com/code/jhoward/first-steps-road-to-the-top-part-1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75eadfab",
   "metadata": {},
   "source": [
    "## Memory and gradient accumulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7535345",
   "metadata": {},
   "source": [
    "First we'll repeat the steps we used last time to access the data and ensure all the latest libraries are installed, and we'll also grab the files we'll need for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c8e2512",
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [],
   "source": [
    "comp = 'paddy-disease-classification'\n",
    "path = setup_comp(comp, install='fastai \"timm>=0.6.2.dev0\"')\n",
    "from fastai.vision.all import *\n",
    "set_seed(42)\n",
    "\n",
    "tst_files = get_image_files(path/'test_images').sorted()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d983950a",
   "metadata": {},
   "source": [
    "In this analysis our goal will be to train an ensemble of larger models with larger inputs. The challenge when training such models is generally GPU memory. Kaggle GPUs have 16280MiB of memory available, as at the time of writing. I like to try out my notebooks on my home PC, then upload them -- but I still need them to run OK on Kaggle (especially if it's a code competition, where this is required). My home PC has 24GiB cards, so just because it runs OK at home doesn't mean it'll run OK on Kaggle.\n",
    " \n",
    "It's really helpful to be able to quickly try a few models and image sizes and find out what will run successfully. To make this quick, we can just grab a small subset of the data for running short epochs -- the memory use will still be the same, but it'll be much faster.\n",
    "\n",
    "One easy way to do this is to simply pick a category with few files in it. Here's our options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16c330ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "normal                      1764\n",
       "blast                       1738\n",
       "hispa                       1594\n",
       "dead_heart                  1442\n",
       "tungro                      1088\n",
       "brown_spot                   965\n",
       "downy_mildew                 620\n",
       "bacterial_leaf_blight        479\n",
       "bacterial_leaf_streak        380\n",
       "bacterial_panicle_blight     337\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/'train.csv')\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2350bf5f",
   "metadata": {},
   "source": [
    "Let's use *bacterial_panicle_blight* since it's the smallest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2231c84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_path = path/'train_images'/'bacterial_panicle_blight'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cf7cc3",
   "metadata": {},
   "source": [
    "Now we'll set up a `train` function which is very similar to the steps we used for training in the last notebook. But there's a few significant differences...\n",
    "\n",
    "The first is that I'm using a `finetune` argument to pick whether we are going to run the `fine_tune()` method, or the `fit_one_cycle()` method -- the latter is faster since it doesn't do an initial fine-tuning of the head. When we fine tune in this function I also have it calculate and return the TTA predictions on the test set, since later on we'll be ensembling the TTA results of a number of models. Note also that we no longer have `seed=42` in the `ImageDataLoaders` line -- that means we'll have different training and validation sets each time we call this. That's what we'll want for ensembling, since it means that each model will use slightly different data.\n",
    "\n",
    "The more important change is that I've added an `accum` argument to implement *gradient accumulation*. As you'll see in the code below, this does two things:\n",
    "\n",
    "1. Divide the batch size by `accum`\n",
    "1. Add the `GradientAccumulation` callback, passing in `accum`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73c61814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(arch, size, item=Resize(480, method='squish'), accum=1, finetune=True, epochs=12):\n",
    "    dls = ImageDataLoaders.from_folder(trn_path, valid_pct=0.2, item_tfms=item,\n",
    "        batch_tfms=aug_transforms(size=size, min_scale=0.75), bs=64//accum)\n",
    "    cbs = GradientAccumulation(64) if accum else []\n",
    "    learn = vision_learner(dls, arch, metrics=error_rate, cbs=cbs).to_fp16()\n",
    "    if finetune:\n",
    "        learn.fine_tune(epochs, 0.01)\n",
    "        return learn.tta(dl=dls.test_dl(tst_files))\n",
    "    else:\n",
    "        learn.unfreeze()\n",
    "        learn.fit_one_cycle(epochs, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f70fefc-a39f-4458-95e4-02d2672f9e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tfms=[RandomResizedCrop(128), Flip(), Normalize.from_stats(*imagenet_stats)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb24c71",
   "metadata": {},
   "source": [
    "*Gradient accumulation* refers to a very simple trick: rather than updating the model weights after every batch based on that batch's gradients, instead keep *accumulating* (adding up) the gradients for a few batches, and them update the model weights with those accumulated gradients. In fastai, the parameter you pass to `GradientAccumulation` defines how many batches of gradients are accumulated. Since we're adding up the gradients over `accum` batches, we therefore need to divide the batch size by that same number. The resulting training loop is nearly mathematically identical to using the original batch size, but the amount of memory used is the same as using a batch size `accum` times smaller!\n",
    "\n",
    "For instance, here's a basic example of a single epoch of a training loop without gradient accumulation:\n",
    "\n",
    "```python\n",
    "for x,y in dl:\n",
    "    calc_loss(coeffs, x, y).backward()\n",
    "    coeffs.data.sub_(coeffs.grad * lr)\n",
    "    coeffs.grad.zero_()\n",
    "```\n",
    "\n",
    "Here's the same thing, but with gradient accumulation added (assuming a target effective batch size of 64):\n",
    "\n",
    "```python\n",
    "count = 0            # track count of items seen since last weight update\n",
    "for x,y in dl:\n",
    "    count += len(x)  # update count based on this minibatch size\n",
    "    calc_loss(coeffs, x, y).backward()\n",
    "    if count>64:     # count is greater than accumulation target, so do weight update\n",
    "        coeffs.data.sub_(coeffs.grad * lr)\n",
    "        coeffs.grad.zero_()\n",
    "        count=0      # reset count\n",
    "```\n",
    "\n",
    "The full implementation in fastai is only a few lines of code -- here's the [source code](https://github.com/fastai/fastai/blob/master/fastai/callback/training.py#L26).\n",
    "\n",
    "To see the impact of gradient accumulation, consider this small model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd372be6-3bd4-4acd-8df4-0d79fe278600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"  # Removes MPS memory cap\n",
    "torch.mps.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e656c0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not do one pass in your dataloader, there is something wrong in it. Please see the stack trace below:\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "The operator 'aten::_linalg_solve_ex.result' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconvnext_small_in22k\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m128\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, accum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, finetune\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(arch, size, item, accum, finetune, epochs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(arch, size, item\u001b[38;5;241m=\u001b[39mResize(\u001b[38;5;241m480\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquish\u001b[39m\u001b[38;5;124m'\u001b[39m), accum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, finetune\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     dls \u001b[38;5;241m=\u001b[39m ImageDataLoaders\u001b[38;5;241m.\u001b[39mfrom_folder(trn_path, valid_pct\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, item_tfms\u001b[38;5;241m=\u001b[39mitem,\n\u001b[1;32m      3\u001b[0m         batch_tfms\u001b[38;5;241m=\u001b[39maug_transforms(size\u001b[38;5;241m=\u001b[39msize, min_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.75\u001b[39m), bs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39maccum)\n\u001b[1;32m      4\u001b[0m     cbs \u001b[38;5;241m=\u001b[39m GradientAccumulation(\u001b[38;5;241m64\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m accum \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m      5\u001b[0m     learn \u001b[38;5;241m=\u001b[39m vision_learner(dls, arch, metrics\u001b[38;5;241m=\u001b[39merror_rate, cbs\u001b[38;5;241m=\u001b[39mcbs)\u001b[38;5;241m.\u001b[39mto_fp16()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/vision/data.py:125\u001b[0m, in \u001b[0;36mImageDataLoaders.from_folder\u001b[0;34m(cls, path, train, valid, valid_pct, seed, vocab, item_tfms, batch_tfms, img_cls, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m get_items \u001b[38;5;241m=\u001b[39m get_image_files \u001b[38;5;28;01mif\u001b[39;00m valid_pct \u001b[38;5;28;01melse\u001b[39;00m partial(get_image_files, folders\u001b[38;5;241m=\u001b[39m[train, valid])\n\u001b[1;32m    119\u001b[0m dblock \u001b[38;5;241m=\u001b[39m DataBlock(blocks\u001b[38;5;241m=\u001b[39m(ImageBlock(img_cls), CategoryBlock(vocab\u001b[38;5;241m=\u001b[39mvocab)),\n\u001b[1;32m    120\u001b[0m                    get_items\u001b[38;5;241m=\u001b[39mget_items,\n\u001b[1;32m    121\u001b[0m                    splitter\u001b[38;5;241m=\u001b[39msplitter,\n\u001b[1;32m    122\u001b[0m                    get_y\u001b[38;5;241m=\u001b[39mparent_label,\n\u001b[1;32m    123\u001b[0m                    item_tfms\u001b[38;5;241m=\u001b[39mitem_tfms,\n\u001b[1;32m    124\u001b[0m                    batch_tfms\u001b[38;5;241m=\u001b[39mbatch_tfms)\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_dblock(dblock, path, path\u001b[38;5;241m=\u001b[39mpath, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/data/core.py:275\u001b[0m, in \u001b[0;36mDataLoaders.from_dblock\u001b[0;34m(cls, dblock, source, path, bs, val_bs, shuffle, device, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_dblock\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \n\u001b[1;32m    266\u001b[0m     dblock, \u001b[38;5;66;03m# `DataBlock` object\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    274\u001b[0m ):\n\u001b[0;32m--> 275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dblock\u001b[38;5;241m.\u001b[39mdataloaders(source, path\u001b[38;5;241m=\u001b[39mpath, bs\u001b[38;5;241m=\u001b[39mbs, val_bs\u001b[38;5;241m=\u001b[39mval_bs, shuffle\u001b[38;5;241m=\u001b[39mshuffle, device\u001b[38;5;241m=\u001b[39mdevice, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/data/block.py:159\u001b[0m, in \u001b[0;36mDataBlock.dataloaders\u001b[0;34m(self, source, path, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m dsets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatasets(source, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m    158\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m: verbose}\n\u001b[0;32m--> 159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dsets\u001b[38;5;241m.\u001b[39mdataloaders(path\u001b[38;5;241m=\u001b[39mpath, after_item\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_tfms, after_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_tfms, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/data/core.py:328\u001b[0m, in \u001b[0;36mFilteredBase.dataloaders\u001b[0;34m(self, bs, shuffle_train, shuffle, val_shuffle, n, path, dl_type, dl_kwargs, device, drop_last, val_bs, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m dl \u001b[38;5;241m=\u001b[39m dl_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubset(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmerge(kwargs,def_kwargs, dl_kwargs[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m    327\u001b[0m def_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbs\u001b[39m\u001b[38;5;124m'\u001b[39m:bs \u001b[38;5;28;01mif\u001b[39;00m val_bs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m val_bs,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshuffle\u001b[39m\u001b[38;5;124m'\u001b[39m:val_shuffle,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrop_last\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mFalse\u001b[39;00m}\n\u001b[0;32m--> 328\u001b[0m dls \u001b[38;5;241m=\u001b[39m [dl] \u001b[38;5;241m+\u001b[39m [dl\u001b[38;5;241m.\u001b[39mnew(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubset(i), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmerge(kwargs,def_kwargs,val_kwargs,dl_kwargs[i]))\n\u001b[1;32m    329\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_subsets)]\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbunch_type(\u001b[38;5;241m*\u001b[39mdls, path\u001b[38;5;241m=\u001b[39mpath, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/data/core.py:99\u001b[0m, in \u001b[0;36mTfmdDL.new\u001b[0;34m(self, dataset, cls, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_n_inp\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_types\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_one_pass()\n\u001b[1;32m    100\u001b[0m         res\u001b[38;5;241m.\u001b[39m_n_inp,res\u001b[38;5;241m.\u001b[39m_types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_inp,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_types\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e: \n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/data/core.py:82\u001b[0m, in \u001b[0;36mTfmdDL._one_pass\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_batch([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_item(\u001b[38;5;28;01mNone\u001b[39;00m)])\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: b \u001b[38;5;241m=\u001b[39m to_device(b, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 82\u001b[0m its \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter_batch(b)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(its, (\u001b[38;5;28mlist\u001b[39m,\u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(its)\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(its)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_types \u001b[38;5;241m=\u001b[39m explode_types(its)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastcore/transform.py:210\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mts\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;241m.\u001b[39msorted(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, o): \u001b[38;5;28;01mreturn\u001b[39;00m compose_tfms(o, tfms\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs, split_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_idx)\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m -> \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([f\u001b[38;5;241m.\u001b[39mname\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mf\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mf\u001b[38;5;241m.\u001b[39mname\u001b[38;5;250m \u001b[39m\u001b[38;5;241m!=\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnoop\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m,i): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs[i]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastcore/transform.py:160\u001b[0m, in \u001b[0;36mcompose_tfms\u001b[0;34m(x, tfms, is_enc, reverse, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m tfms:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_enc: f \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mdecode\n\u001b[0;32m--> 160\u001b[0m     x \u001b[38;5;241m=\u001b[39m f(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/vision/augment.py:51\u001b[0m, in \u001b[0;36mRandTransform.__call__\u001b[0;34m(self, b, split_idx, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m     46\u001b[0m     b, \n\u001b[1;32m     47\u001b[0m     split_idx:\u001b[38;5;28mint\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;66;03m# Index of the train/valid dataset\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     49\u001b[0m ):\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbefore_call(b, split_idx\u001b[38;5;241m=\u001b[39msplit_idx)\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(b, split_idx\u001b[38;5;241m=\u001b[39msplit_idx, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo \u001b[38;5;28;01melse\u001b[39;00m b\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastcore/transform.py:83\u001b[0m, in \u001b[0;36mTransform.__call__\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mname\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_name\u001b[39m\u001b[38;5;124m'\u001b[39m, _get_name(\u001b[38;5;28mself\u001b[39m))\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencodes\u001b[39m\u001b[38;5;124m'\u001b[39m, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m  (\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecodes\u001b[39m\u001b[38;5;124m'\u001b[39m, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mencodes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencodes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mdecodes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecodes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastcore/transform.py:93\u001b[0m, in \u001b[0;36mTransform._call\u001b[0;34m(self, fn, x, split_idx, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, x, split_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m split_idx\u001b[38;5;241m!=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_idx \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn), x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastcore/transform.py:100\u001b[0m, in \u001b[0;36mTransform._do_call\u001b[0;34m(self, f, x, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m     ret \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreturns(x) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturns\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(f(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), x, ret)\n\u001b[0;32m--> 100\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(f, x_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m x_ \u001b[38;5;129;01min\u001b[39;00m x)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(res, x)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastcore/transform.py:100\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     98\u001b[0m     ret \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreturns(x) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturns\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(f(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), x, ret)\n\u001b[0;32m--> 100\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(f, x_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m x_ \u001b[38;5;129;01min\u001b[39;00m x)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(res, x)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastcore/transform.py:99\u001b[0m, in \u001b[0;36mTransform._do_call\u001b[0;34m(self, f, x, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m     98\u001b[0m     ret \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreturns(x) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturns\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(f(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), x, ret)\n\u001b[1;32m    100\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(f, x_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m x_ \u001b[38;5;129;01min\u001b[39;00m x)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(res, x)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastcore/dispatch.py:122\u001b[0m, in \u001b[0;36mTypeDispatch.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minst \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: f \u001b[38;5;241m=\u001b[39m MethodType(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minst)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mowner \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: f \u001b[38;5;241m=\u001b[39m MethodType(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mowner)\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/vision/augment.py:503\u001b[0m, in \u001b[0;36mAffineCoordTfm.encodes\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    500\u001b[0m     coord_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoord_fs)\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_idx \u001b[38;5;28;01melse\u001b[39;00m partial(compose_tfms, tfms\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoord_fs, reverse\u001b[38;5;241m=\u001b[39mreverse)\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39maffine_coord(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmat, coord_func, sz\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize, mode\u001b[38;5;241m=\u001b[39mmode, pad_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_mode, align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malign_corners)\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencodes\u001b[39m(\u001b[38;5;28mself\u001b[39m, x:TensorImage): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode)\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencodes\u001b[39m(\u001b[38;5;28mself\u001b[39m, x:TensorMask):  \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode_mask)\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencodes\u001b[39m(\u001b[38;5;28mself\u001b[39m, x:TensorPoint\u001b[38;5;241m|\u001b[39mTensorBBox): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/vision/augment.py:501\u001b[0m, in \u001b[0;36mAffineCoordTfm._encode\u001b[0;34m(self, x, mode, reverse)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, mode, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    500\u001b[0m     coord_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoord_fs)\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_idx \u001b[38;5;28;01melse\u001b[39;00m partial(compose_tfms, tfms\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoord_fs, reverse\u001b[38;5;241m=\u001b[39mreverse)\n\u001b[0;32m--> 501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39maffine_coord(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmat, coord_func, sz\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize, mode\u001b[38;5;241m=\u001b[39mmode, pad_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_mode, align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malign_corners)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/vision/augment.py:392\u001b[0m, in \u001b[0;36maffine_coord\u001b[0;34m(x, mat, coord_tfm, sz, mode, pad_mode, align_corners)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mat \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: mat \u001b[38;5;241m=\u001b[39m _init_mat(x)[:,:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    391\u001b[0m coords \u001b[38;5;241m=\u001b[39m affine_grid(mat, x\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m size, align_corners\u001b[38;5;241m=\u001b[39malign_corners)\n\u001b[0;32m--> 392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m coord_tfm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: coords \u001b[38;5;241m=\u001b[39m coord_tfm(coords)\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TensorImage(_grid_sample(x, coords, mode\u001b[38;5;241m=\u001b[39mmode, padding_mode\u001b[38;5;241m=\u001b[39mpad_mode, align_corners\u001b[38;5;241m=\u001b[39malign_corners))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastcore/transform.py:160\u001b[0m, in \u001b[0;36mcompose_tfms\u001b[0;34m(x, tfms, is_enc, reverse, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m tfms:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_enc: f \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mdecode\n\u001b[0;32m--> 160\u001b[0m     x \u001b[38;5;241m=\u001b[39m f(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/vision/augment.py:872\u001b[0m, in \u001b[0;36m_WarpCoord.__call__\u001b[0;34m(self, x, invert)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, invert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 872\u001b[0m     coeffs \u001b[38;5;241m=\u001b[39m find_coeffs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarg_pts, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_pts) \u001b[38;5;28;01mif\u001b[39;00m invert \u001b[38;5;28;01melse\u001b[39;00m find_coeffs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_pts, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarg_pts)\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m apply_perspective(x, coeffs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/vision/augment.py:836\u001b[0m, in \u001b[0;36mfind_coeffs\u001b[0;34m(p1, p2)\u001b[0m\n\u001b[1;32m    834\u001b[0m A \u001b[38;5;241m=\u001b[39m stack(m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    835\u001b[0m B \u001b[38;5;241m=\u001b[39m p1\u001b[38;5;241m.\u001b[39mview(p1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 836\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m solve(A,B)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/vision/augment.py:819\u001b[0m, in \u001b[0;36msolve\u001b[0;34m(A, B)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msolve\u001b[39m(A,B):\n\u001b[0;32m--> 819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39msolve(A,B)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/torch_core.py:384\u001b[0m, in \u001b[0;36mTensorBase.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__str__\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28mprint\u001b[39m(func, types, args, kwargs)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _torch_handled(args, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_opt, func): types \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mTensor,)\n\u001b[0;32m--> 384\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m__torch_function__(func, types, args, ifnone(kwargs, {}))\n\u001b[1;32m    385\u001b[0m dict_objs \u001b[38;5;241m=\u001b[39m _find_args(args) \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m _find_args(\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mtype\u001b[39m(res),TensorBase) \u001b[38;5;129;01mand\u001b[39;00m dict_objs: res\u001b[38;5;241m.\u001b[39mset_meta(dict_objs[\u001b[38;5;241m0\u001b[39m],as_copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/_tensor.py:1512\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[0;32m-> 1512\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1514\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: The operator 'aten::_linalg_solve_ex.result' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS."
     ]
    }
   ],
   "source": [
    "train('convnext_small_in22k', 128, epochs=1, accum=1, finetune=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a618a67-2f64-4926-b18e-e3e609648182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6225920"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mps.current_allocated_memory()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f39ee28",
   "metadata": {},
   "source": [
    "Let's create a function to find out how much memory it used, and also to then clear out the memory for the next run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d6b0e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated Memory: 0.00 MB\n"
     ]
    }
   ],
   "source": [
    "# import gc\n",
    "# def report_gpu():\n",
    "#     print(torch.cuda.list_gpu_processes())\n",
    "#     gc.collect()\n",
    "#     torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "def report_gpu():\n",
    "    if torch.backends.mps.is_available():\n",
    "        allocated = torch.mps.current_allocated_memory() / 1024**2  # Convert to MB\n",
    "        print(f\"Allocated Memory: {allocated:.2f} MB\")\n",
    "        \n",
    "        gc.collect()  # Run garbage collection\n",
    "        torch.mps.empty_cache()  # Clear MPS cache\n",
    "    else:\n",
    "        print(\"MPS is not available on this device.\")\n",
    "\n",
    "# Run the function\n",
    "report_gpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c0b2441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated Memory: 0.00 MB\n"
     ]
    }
   ],
   "source": [
    "report_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4c2d43",
   "metadata": {},
   "source": [
    "So with `accum=1` the GPU used around 5GB RAM. Let's try `accum=2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0a5f501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not do one pass in your dataloader, there is something wrong in it. Please see the stack trace below:\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "The operator 'aten::_linalg_solve_ex.result' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconvnext_small_in22k\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m128\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, accum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, finetune\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m report_gpu()\n",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(arch, size, item, accum, finetune, epochs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(arch, size, item\u001b[38;5;241m=\u001b[39mResize(\u001b[38;5;241m480\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquish\u001b[39m\u001b[38;5;124m'\u001b[39m), accum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, finetune\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     dls \u001b[38;5;241m=\u001b[39m ImageDataLoaders\u001b[38;5;241m.\u001b[39mfrom_folder(trn_path, valid_pct\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, item_tfms\u001b[38;5;241m=\u001b[39mitem,\n\u001b[1;32m      3\u001b[0m         batch_tfms\u001b[38;5;241m=\u001b[39maug_transforms(size\u001b[38;5;241m=\u001b[39msize, min_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.75\u001b[39m), bs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39maccum)\n\u001b[1;32m      4\u001b[0m     cbs \u001b[38;5;241m=\u001b[39m GradientAccumulation(\u001b[38;5;241m64\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m accum \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m      5\u001b[0m     learn \u001b[38;5;241m=\u001b[39m vision_learner(dls, arch, metrics\u001b[38;5;241m=\u001b[39merror_rate, cbs\u001b[38;5;241m=\u001b[39mcbs)\u001b[38;5;241m.\u001b[39mto_fp16()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/vision/data.py:125\u001b[0m, in \u001b[0;36mImageDataLoaders.from_folder\u001b[0;34m(cls, path, train, valid, valid_pct, seed, vocab, item_tfms, batch_tfms, img_cls, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m get_items \u001b[38;5;241m=\u001b[39m get_image_files \u001b[38;5;28;01mif\u001b[39;00m valid_pct \u001b[38;5;28;01melse\u001b[39;00m partial(get_image_files, folders\u001b[38;5;241m=\u001b[39m[train, valid])\n\u001b[1;32m    119\u001b[0m dblock \u001b[38;5;241m=\u001b[39m DataBlock(blocks\u001b[38;5;241m=\u001b[39m(ImageBlock(img_cls), CategoryBlock(vocab\u001b[38;5;241m=\u001b[39mvocab)),\n\u001b[1;32m    120\u001b[0m                    get_items\u001b[38;5;241m=\u001b[39mget_items,\n\u001b[1;32m    121\u001b[0m                    splitter\u001b[38;5;241m=\u001b[39msplitter,\n\u001b[1;32m    122\u001b[0m                    get_y\u001b[38;5;241m=\u001b[39mparent_label,\n\u001b[1;32m    123\u001b[0m                    item_tfms\u001b[38;5;241m=\u001b[39mitem_tfms,\n\u001b[1;32m    124\u001b[0m                    batch_tfms\u001b[38;5;241m=\u001b[39mbatch_tfms)\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_dblock(dblock, path, path\u001b[38;5;241m=\u001b[39mpath, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/data/core.py:275\u001b[0m, in \u001b[0;36mDataLoaders.from_dblock\u001b[0;34m(cls, dblock, source, path, bs, val_bs, shuffle, device, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_dblock\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \n\u001b[1;32m    266\u001b[0m     dblock, \u001b[38;5;66;03m# `DataBlock` object\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    274\u001b[0m ):\n\u001b[0;32m--> 275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dblock\u001b[38;5;241m.\u001b[39mdataloaders(source, path\u001b[38;5;241m=\u001b[39mpath, bs\u001b[38;5;241m=\u001b[39mbs, val_bs\u001b[38;5;241m=\u001b[39mval_bs, shuffle\u001b[38;5;241m=\u001b[39mshuffle, device\u001b[38;5;241m=\u001b[39mdevice, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/data/block.py:159\u001b[0m, in \u001b[0;36mDataBlock.dataloaders\u001b[0;34m(self, source, path, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m dsets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatasets(source, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m    158\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m: verbose}\n\u001b[0;32m--> 159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dsets\u001b[38;5;241m.\u001b[39mdataloaders(path\u001b[38;5;241m=\u001b[39mpath, after_item\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_tfms, after_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_tfms, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/data/core.py:328\u001b[0m, in \u001b[0;36mFilteredBase.dataloaders\u001b[0;34m(self, bs, shuffle_train, shuffle, val_shuffle, n, path, dl_type, dl_kwargs, device, drop_last, val_bs, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m dl \u001b[38;5;241m=\u001b[39m dl_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubset(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmerge(kwargs,def_kwargs, dl_kwargs[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m    327\u001b[0m def_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbs\u001b[39m\u001b[38;5;124m'\u001b[39m:bs \u001b[38;5;28;01mif\u001b[39;00m val_bs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m val_bs,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshuffle\u001b[39m\u001b[38;5;124m'\u001b[39m:val_shuffle,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrop_last\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mFalse\u001b[39;00m}\n\u001b[0;32m--> 328\u001b[0m dls \u001b[38;5;241m=\u001b[39m [dl] \u001b[38;5;241m+\u001b[39m [dl\u001b[38;5;241m.\u001b[39mnew(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubset(i), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmerge(kwargs,def_kwargs,val_kwargs,dl_kwargs[i]))\n\u001b[1;32m    329\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_subsets)]\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbunch_type(\u001b[38;5;241m*\u001b[39mdls, path\u001b[38;5;241m=\u001b[39mpath, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/data/core.py:99\u001b[0m, in \u001b[0;36mTfmdDL.new\u001b[0;34m(self, dataset, cls, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_n_inp\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_types\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_one_pass()\n\u001b[1;32m    100\u001b[0m         res\u001b[38;5;241m.\u001b[39m_n_inp,res\u001b[38;5;241m.\u001b[39m_types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_inp,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_types\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e: \n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/data/core.py:82\u001b[0m, in \u001b[0;36mTfmdDL._one_pass\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_batch([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_item(\u001b[38;5;28;01mNone\u001b[39;00m)])\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: b \u001b[38;5;241m=\u001b[39m to_device(b, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 82\u001b[0m its \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter_batch(b)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(its, (\u001b[38;5;28mlist\u001b[39m,\u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(its)\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(its)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_types \u001b[38;5;241m=\u001b[39m explode_types(its)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastcore/transform.py:210\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mts\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;241m.\u001b[39msorted(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, o): \u001b[38;5;28;01mreturn\u001b[39;00m compose_tfms(o, tfms\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs, split_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_idx)\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m -> \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([f\u001b[38;5;241m.\u001b[39mname\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mf\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mf\u001b[38;5;241m.\u001b[39mname\u001b[38;5;250m \u001b[39m\u001b[38;5;241m!=\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnoop\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m,i): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs[i]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastcore/transform.py:160\u001b[0m, in \u001b[0;36mcompose_tfms\u001b[0;34m(x, tfms, is_enc, reverse, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m tfms:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_enc: f \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mdecode\n\u001b[0;32m--> 160\u001b[0m     x \u001b[38;5;241m=\u001b[39m f(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/vision/augment.py:51\u001b[0m, in \u001b[0;36mRandTransform.__call__\u001b[0;34m(self, b, split_idx, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m     46\u001b[0m     b, \n\u001b[1;32m     47\u001b[0m     split_idx:\u001b[38;5;28mint\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;66;03m# Index of the train/valid dataset\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     49\u001b[0m ):\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbefore_call(b, split_idx\u001b[38;5;241m=\u001b[39msplit_idx)\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(b, split_idx\u001b[38;5;241m=\u001b[39msplit_idx, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo \u001b[38;5;28;01melse\u001b[39;00m b\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastcore/transform.py:83\u001b[0m, in \u001b[0;36mTransform.__call__\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mname\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_name\u001b[39m\u001b[38;5;124m'\u001b[39m, _get_name(\u001b[38;5;28mself\u001b[39m))\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencodes\u001b[39m\u001b[38;5;124m'\u001b[39m, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m  (\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecodes\u001b[39m\u001b[38;5;124m'\u001b[39m, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mencodes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencodes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mdecodes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecodes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastcore/transform.py:93\u001b[0m, in \u001b[0;36mTransform._call\u001b[0;34m(self, fn, x, split_idx, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, x, split_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m split_idx\u001b[38;5;241m!=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_idx \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn), x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastcore/transform.py:100\u001b[0m, in \u001b[0;36mTransform._do_call\u001b[0;34m(self, f, x, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m     ret \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreturns(x) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturns\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(f(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), x, ret)\n\u001b[0;32m--> 100\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(f, x_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m x_ \u001b[38;5;129;01min\u001b[39;00m x)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(res, x)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastcore/transform.py:100\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     98\u001b[0m     ret \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreturns(x) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturns\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(f(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), x, ret)\n\u001b[0;32m--> 100\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(f, x_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m x_ \u001b[38;5;129;01min\u001b[39;00m x)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(res, x)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastcore/transform.py:99\u001b[0m, in \u001b[0;36mTransform._do_call\u001b[0;34m(self, f, x, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m     98\u001b[0m     ret \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreturns(x) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturns\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(f(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), x, ret)\n\u001b[1;32m    100\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(f, x_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m x_ \u001b[38;5;129;01min\u001b[39;00m x)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(res, x)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastcore/dispatch.py:122\u001b[0m, in \u001b[0;36mTypeDispatch.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minst \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: f \u001b[38;5;241m=\u001b[39m MethodType(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minst)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mowner \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: f \u001b[38;5;241m=\u001b[39m MethodType(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mowner)\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/vision/augment.py:503\u001b[0m, in \u001b[0;36mAffineCoordTfm.encodes\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    500\u001b[0m     coord_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoord_fs)\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_idx \u001b[38;5;28;01melse\u001b[39;00m partial(compose_tfms, tfms\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoord_fs, reverse\u001b[38;5;241m=\u001b[39mreverse)\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39maffine_coord(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmat, coord_func, sz\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize, mode\u001b[38;5;241m=\u001b[39mmode, pad_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_mode, align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malign_corners)\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencodes\u001b[39m(\u001b[38;5;28mself\u001b[39m, x:TensorImage): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode)\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencodes\u001b[39m(\u001b[38;5;28mself\u001b[39m, x:TensorMask):  \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode_mask)\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencodes\u001b[39m(\u001b[38;5;28mself\u001b[39m, x:TensorPoint\u001b[38;5;241m|\u001b[39mTensorBBox): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/vision/augment.py:501\u001b[0m, in \u001b[0;36mAffineCoordTfm._encode\u001b[0;34m(self, x, mode, reverse)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, mode, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    500\u001b[0m     coord_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoord_fs)\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_idx \u001b[38;5;28;01melse\u001b[39;00m partial(compose_tfms, tfms\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoord_fs, reverse\u001b[38;5;241m=\u001b[39mreverse)\n\u001b[0;32m--> 501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39maffine_coord(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmat, coord_func, sz\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize, mode\u001b[38;5;241m=\u001b[39mmode, pad_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_mode, align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malign_corners)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/vision/augment.py:392\u001b[0m, in \u001b[0;36maffine_coord\u001b[0;34m(x, mat, coord_tfm, sz, mode, pad_mode, align_corners)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mat \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: mat \u001b[38;5;241m=\u001b[39m _init_mat(x)[:,:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    391\u001b[0m coords \u001b[38;5;241m=\u001b[39m affine_grid(mat, x\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m size, align_corners\u001b[38;5;241m=\u001b[39malign_corners)\n\u001b[0;32m--> 392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m coord_tfm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: coords \u001b[38;5;241m=\u001b[39m coord_tfm(coords)\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TensorImage(_grid_sample(x, coords, mode\u001b[38;5;241m=\u001b[39mmode, padding_mode\u001b[38;5;241m=\u001b[39mpad_mode, align_corners\u001b[38;5;241m=\u001b[39malign_corners))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastcore/transform.py:160\u001b[0m, in \u001b[0;36mcompose_tfms\u001b[0;34m(x, tfms, is_enc, reverse, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m tfms:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_enc: f \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mdecode\n\u001b[0;32m--> 160\u001b[0m     x \u001b[38;5;241m=\u001b[39m f(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/vision/augment.py:872\u001b[0m, in \u001b[0;36m_WarpCoord.__call__\u001b[0;34m(self, x, invert)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, invert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 872\u001b[0m     coeffs \u001b[38;5;241m=\u001b[39m find_coeffs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarg_pts, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_pts) \u001b[38;5;28;01mif\u001b[39;00m invert \u001b[38;5;28;01melse\u001b[39;00m find_coeffs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_pts, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarg_pts)\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m apply_perspective(x, coeffs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/vision/augment.py:836\u001b[0m, in \u001b[0;36mfind_coeffs\u001b[0;34m(p1, p2)\u001b[0m\n\u001b[1;32m    834\u001b[0m A \u001b[38;5;241m=\u001b[39m stack(m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    835\u001b[0m B \u001b[38;5;241m=\u001b[39m p1\u001b[38;5;241m.\u001b[39mview(p1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 836\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m solve(A,B)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/vision/augment.py:819\u001b[0m, in \u001b[0;36msolve\u001b[0;34m(A, B)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msolve\u001b[39m(A,B):\n\u001b[0;32m--> 819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39msolve(A,B)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/torch_core.py:384\u001b[0m, in \u001b[0;36mTensorBase.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__str__\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28mprint\u001b[39m(func, types, args, kwargs)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _torch_handled(args, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_opt, func): types \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mTensor,)\n\u001b[0;32m--> 384\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m__torch_function__(func, types, args, ifnone(kwargs, {}))\n\u001b[1;32m    385\u001b[0m dict_objs \u001b[38;5;241m=\u001b[39m _find_args(args) \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m _find_args(\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mtype\u001b[39m(res),TensorBase) \u001b[38;5;129;01mand\u001b[39;00m dict_objs: res\u001b[38;5;241m.\u001b[39mset_meta(dict_objs[\u001b[38;5;241m0\u001b[39m],as_copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/_tensor.py:1512\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[0;32m-> 1512\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1514\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: The operator 'aten::_linalg_solve_ex.result' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS."
     ]
    }
   ],
   "source": [
    "train('convnext_small_in22k', 128, epochs=1, accum=2, finetune=False)\n",
    "report_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f03cc62",
   "metadata": {},
   "source": [
    "As you see, the RAM usage has now gone down to 4GB. It's not halved since there's other overhead involved (for larger models this overhead is likely to be relatively lower).\n",
    "\n",
    "Let's try `4`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5afc86bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not do one pass in your dataloader, there is something wrong in it. Please see the stack trace below:\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "The operator 'aten::_linalg_solve_ex.result' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconvnext_small_in22k\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m128\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, accum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, finetune\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m report_gpu()\n",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(arch, size, item, accum, finetune, epochs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(arch, size, item\u001b[38;5;241m=\u001b[39mResize(\u001b[38;5;241m480\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msquish\u001b[39m\u001b[38;5;124m'\u001b[39m), accum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, finetune\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     dls \u001b[38;5;241m=\u001b[39m ImageDataLoaders\u001b[38;5;241m.\u001b[39mfrom_folder(trn_path, valid_pct\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, item_tfms\u001b[38;5;241m=\u001b[39mitem,\n\u001b[1;32m      3\u001b[0m         batch_tfms\u001b[38;5;241m=\u001b[39maug_transforms(size\u001b[38;5;241m=\u001b[39msize, min_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.75\u001b[39m), bs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39maccum)\n\u001b[1;32m      4\u001b[0m     cbs \u001b[38;5;241m=\u001b[39m GradientAccumulation(\u001b[38;5;241m64\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m accum \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m      5\u001b[0m     learn \u001b[38;5;241m=\u001b[39m vision_learner(dls, arch, metrics\u001b[38;5;241m=\u001b[39merror_rate, cbs\u001b[38;5;241m=\u001b[39mcbs)\u001b[38;5;241m.\u001b[39mto_fp16()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/vision/data.py:125\u001b[0m, in \u001b[0;36mImageDataLoaders.from_folder\u001b[0;34m(cls, path, train, valid, valid_pct, seed, vocab, item_tfms, batch_tfms, img_cls, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m get_items \u001b[38;5;241m=\u001b[39m get_image_files \u001b[38;5;28;01mif\u001b[39;00m valid_pct \u001b[38;5;28;01melse\u001b[39;00m partial(get_image_files, folders\u001b[38;5;241m=\u001b[39m[train, valid])\n\u001b[1;32m    119\u001b[0m dblock \u001b[38;5;241m=\u001b[39m DataBlock(blocks\u001b[38;5;241m=\u001b[39m(ImageBlock(img_cls), CategoryBlock(vocab\u001b[38;5;241m=\u001b[39mvocab)),\n\u001b[1;32m    120\u001b[0m                    get_items\u001b[38;5;241m=\u001b[39mget_items,\n\u001b[1;32m    121\u001b[0m                    splitter\u001b[38;5;241m=\u001b[39msplitter,\n\u001b[1;32m    122\u001b[0m                    get_y\u001b[38;5;241m=\u001b[39mparent_label,\n\u001b[1;32m    123\u001b[0m                    item_tfms\u001b[38;5;241m=\u001b[39mitem_tfms,\n\u001b[1;32m    124\u001b[0m                    batch_tfms\u001b[38;5;241m=\u001b[39mbatch_tfms)\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_dblock(dblock, path, path\u001b[38;5;241m=\u001b[39mpath, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/data/core.py:275\u001b[0m, in \u001b[0;36mDataLoaders.from_dblock\u001b[0;34m(cls, dblock, source, path, bs, val_bs, shuffle, device, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_dblock\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \n\u001b[1;32m    266\u001b[0m     dblock, \u001b[38;5;66;03m# `DataBlock` object\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    274\u001b[0m ):\n\u001b[0;32m--> 275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dblock\u001b[38;5;241m.\u001b[39mdataloaders(source, path\u001b[38;5;241m=\u001b[39mpath, bs\u001b[38;5;241m=\u001b[39mbs, val_bs\u001b[38;5;241m=\u001b[39mval_bs, shuffle\u001b[38;5;241m=\u001b[39mshuffle, device\u001b[38;5;241m=\u001b[39mdevice, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/data/block.py:159\u001b[0m, in \u001b[0;36mDataBlock.dataloaders\u001b[0;34m(self, source, path, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m dsets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatasets(source, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m    158\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m: verbose}\n\u001b[0;32m--> 159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dsets\u001b[38;5;241m.\u001b[39mdataloaders(path\u001b[38;5;241m=\u001b[39mpath, after_item\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_tfms, after_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_tfms, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/data/core.py:328\u001b[0m, in \u001b[0;36mFilteredBase.dataloaders\u001b[0;34m(self, bs, shuffle_train, shuffle, val_shuffle, n, path, dl_type, dl_kwargs, device, drop_last, val_bs, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m dl \u001b[38;5;241m=\u001b[39m dl_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubset(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmerge(kwargs,def_kwargs, dl_kwargs[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m    327\u001b[0m def_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbs\u001b[39m\u001b[38;5;124m'\u001b[39m:bs \u001b[38;5;28;01mif\u001b[39;00m val_bs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m val_bs,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshuffle\u001b[39m\u001b[38;5;124m'\u001b[39m:val_shuffle,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrop_last\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mFalse\u001b[39;00m}\n\u001b[0;32m--> 328\u001b[0m dls \u001b[38;5;241m=\u001b[39m [dl] \u001b[38;5;241m+\u001b[39m [dl\u001b[38;5;241m.\u001b[39mnew(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubset(i), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmerge(kwargs,def_kwargs,val_kwargs,dl_kwargs[i]))\n\u001b[1;32m    329\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_subsets)]\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dbunch_type(\u001b[38;5;241m*\u001b[39mdls, path\u001b[38;5;241m=\u001b[39mpath, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/data/core.py:99\u001b[0m, in \u001b[0;36mTfmdDL.new\u001b[0;34m(self, dataset, cls, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_n_inp\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_types\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_one_pass()\n\u001b[1;32m    100\u001b[0m         res\u001b[38;5;241m.\u001b[39m_n_inp,res\u001b[38;5;241m.\u001b[39m_types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_inp,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_types\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e: \n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/data/core.py:82\u001b[0m, in \u001b[0;36mTfmdDL._one_pass\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_batch([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_item(\u001b[38;5;28;01mNone\u001b[39;00m)])\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: b \u001b[38;5;241m=\u001b[39m to_device(b, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 82\u001b[0m its \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter_batch(b)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_inp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(its, (\u001b[38;5;28mlist\u001b[39m,\u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(its)\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(its)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_types \u001b[38;5;241m=\u001b[39m explode_types(its)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastcore/transform.py:210\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mts\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;241m.\u001b[39msorted(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, o): \u001b[38;5;28;01mreturn\u001b[39;00m compose_tfms(o, tfms\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs, split_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_idx)\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m -> \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([f\u001b[38;5;241m.\u001b[39mname\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mf\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mf\u001b[38;5;241m.\u001b[39mname\u001b[38;5;250m \u001b[39m\u001b[38;5;241m!=\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnoop\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m,i): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs[i]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastcore/transform.py:160\u001b[0m, in \u001b[0;36mcompose_tfms\u001b[0;34m(x, tfms, is_enc, reverse, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m tfms:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_enc: f \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mdecode\n\u001b[0;32m--> 160\u001b[0m     x \u001b[38;5;241m=\u001b[39m f(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/vision/augment.py:51\u001b[0m, in \u001b[0;36mRandTransform.__call__\u001b[0;34m(self, b, split_idx, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m     46\u001b[0m     b, \n\u001b[1;32m     47\u001b[0m     split_idx:\u001b[38;5;28mint\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;66;03m# Index of the train/valid dataset\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     49\u001b[0m ):\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbefore_call(b, split_idx\u001b[38;5;241m=\u001b[39msplit_idx)\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(b, split_idx\u001b[38;5;241m=\u001b[39msplit_idx, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo \u001b[38;5;28;01melse\u001b[39;00m b\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastcore/transform.py:83\u001b[0m, in \u001b[0;36mTransform.__call__\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mname\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_name\u001b[39m\u001b[38;5;124m'\u001b[39m, _get_name(\u001b[38;5;28mself\u001b[39m))\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencodes\u001b[39m\u001b[38;5;124m'\u001b[39m, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m  (\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecodes\u001b[39m\u001b[38;5;124m'\u001b[39m, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mencodes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencodes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mdecodes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecodes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastcore/transform.py:93\u001b[0m, in \u001b[0;36mTransform._call\u001b[0;34m(self, fn, x, split_idx, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, x, split_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m split_idx\u001b[38;5;241m!=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_idx \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn), x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastcore/transform.py:100\u001b[0m, in \u001b[0;36mTransform._do_call\u001b[0;34m(self, f, x, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m     ret \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreturns(x) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturns\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(f(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), x, ret)\n\u001b[0;32m--> 100\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(f, x_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m x_ \u001b[38;5;129;01min\u001b[39;00m x)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(res, x)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastcore/transform.py:100\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     98\u001b[0m     ret \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreturns(x) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturns\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(f(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), x, ret)\n\u001b[0;32m--> 100\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(f, x_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m x_ \u001b[38;5;129;01min\u001b[39;00m x)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(res, x)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastcore/transform.py:99\u001b[0m, in \u001b[0;36mTransform._do_call\u001b[0;34m(self, f, x, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m     98\u001b[0m     ret \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreturns(x) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturns\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(f(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), x, ret)\n\u001b[1;32m    100\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(f, x_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m x_ \u001b[38;5;129;01min\u001b[39;00m x)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retain_type(res, x)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastcore/dispatch.py:122\u001b[0m, in \u001b[0;36mTypeDispatch.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minst \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: f \u001b[38;5;241m=\u001b[39m MethodType(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minst)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mowner \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: f \u001b[38;5;241m=\u001b[39m MethodType(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mowner)\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/vision/augment.py:503\u001b[0m, in \u001b[0;36mAffineCoordTfm.encodes\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    500\u001b[0m     coord_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoord_fs)\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_idx \u001b[38;5;28;01melse\u001b[39;00m partial(compose_tfms, tfms\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoord_fs, reverse\u001b[38;5;241m=\u001b[39mreverse)\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39maffine_coord(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmat, coord_func, sz\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize, mode\u001b[38;5;241m=\u001b[39mmode, pad_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_mode, align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malign_corners)\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencodes\u001b[39m(\u001b[38;5;28mself\u001b[39m, x:TensorImage): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode)\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencodes\u001b[39m(\u001b[38;5;28mself\u001b[39m, x:TensorMask):  \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode_mask)\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencodes\u001b[39m(\u001b[38;5;28mself\u001b[39m, x:TensorPoint\u001b[38;5;241m|\u001b[39mTensorBBox): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/vision/augment.py:501\u001b[0m, in \u001b[0;36mAffineCoordTfm._encode\u001b[0;34m(self, x, mode, reverse)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, mode, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    500\u001b[0m     coord_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoord_fs)\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_idx \u001b[38;5;28;01melse\u001b[39;00m partial(compose_tfms, tfms\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoord_fs, reverse\u001b[38;5;241m=\u001b[39mreverse)\n\u001b[0;32m--> 501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39maffine_coord(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmat, coord_func, sz\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize, mode\u001b[38;5;241m=\u001b[39mmode, pad_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_mode, align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malign_corners)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/vision/augment.py:392\u001b[0m, in \u001b[0;36maffine_coord\u001b[0;34m(x, mat, coord_tfm, sz, mode, pad_mode, align_corners)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mat \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: mat \u001b[38;5;241m=\u001b[39m _init_mat(x)[:,:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    391\u001b[0m coords \u001b[38;5;241m=\u001b[39m affine_grid(mat, x\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m size, align_corners\u001b[38;5;241m=\u001b[39malign_corners)\n\u001b[0;32m--> 392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m coord_tfm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: coords \u001b[38;5;241m=\u001b[39m coord_tfm(coords)\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m TensorImage(_grid_sample(x, coords, mode\u001b[38;5;241m=\u001b[39mmode, padding_mode\u001b[38;5;241m=\u001b[39mpad_mode, align_corners\u001b[38;5;241m=\u001b[39malign_corners))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastcore/transform.py:160\u001b[0m, in \u001b[0;36mcompose_tfms\u001b[0;34m(x, tfms, is_enc, reverse, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m tfms:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_enc: f \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mdecode\n\u001b[0;32m--> 160\u001b[0m     x \u001b[38;5;241m=\u001b[39m f(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/vision/augment.py:872\u001b[0m, in \u001b[0;36m_WarpCoord.__call__\u001b[0;34m(self, x, invert)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, invert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 872\u001b[0m     coeffs \u001b[38;5;241m=\u001b[39m find_coeffs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarg_pts, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_pts) \u001b[38;5;28;01mif\u001b[39;00m invert \u001b[38;5;28;01melse\u001b[39;00m find_coeffs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_pts, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarg_pts)\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m apply_perspective(x, coeffs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/vision/augment.py:836\u001b[0m, in \u001b[0;36mfind_coeffs\u001b[0;34m(p1, p2)\u001b[0m\n\u001b[1;32m    834\u001b[0m A \u001b[38;5;241m=\u001b[39m stack(m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    835\u001b[0m B \u001b[38;5;241m=\u001b[39m p1\u001b[38;5;241m.\u001b[39mview(p1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 836\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m solve(A,B)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/vision/augment.py:819\u001b[0m, in \u001b[0;36msolve\u001b[0;34m(A, B)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msolve\u001b[39m(A,B):\n\u001b[0;32m--> 819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39msolve(A,B)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/fastai/torch_core.py:384\u001b[0m, in \u001b[0;36mTensorBase.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__str__\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28mprint\u001b[39m(func, types, args, kwargs)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _torch_handled(args, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_opt, func): types \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mTensor,)\n\u001b[0;32m--> 384\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m__torch_function__(func, types, args, ifnone(kwargs, {}))\n\u001b[1;32m    385\u001b[0m dict_objs \u001b[38;5;241m=\u001b[39m _find_args(args) \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m _find_args(\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mvalues()))\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mtype\u001b[39m(res),TensorBase) \u001b[38;5;129;01mand\u001b[39;00m dict_objs: res\u001b[38;5;241m.\u001b[39mset_meta(dict_objs[\u001b[38;5;241m0\u001b[39m],as_copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/_tensor.py:1512\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[0;32m-> 1512\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1514\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: The operator 'aten::_linalg_solve_ex.result' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS."
     ]
    }
   ],
   "source": [
    "train('convnext_small_in22k', 128, epochs=1, accum=16, finetune=False)\n",
    "report_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f6c5b8",
   "metadata": {},
   "source": [
    "The memory use is even lower!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7376e138",
   "metadata": {},
   "source": [
    "## Checking memory use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f19e2ff",
   "metadata": {},
   "source": [
    "We'll now check the memory use for each of the architectures and sizes we'll be training later, to ensure they all fit in 16GB RAM. For each of these, I tried `accum=1` first, and then doubled it any time the resulting memory use was over 16GB. As it turns out, `accum=2` was what I needed for every case.\n",
    "\n",
    "First, `convnext_large`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7bf9f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train('convnext_large_in22k', 224, epochs=1, accum=2, finetune=False)\n",
    "report_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adf6d642",
   "metadata": {},
   "outputs": [],
   "source": [
    "train('convnext_large_in22k', (320,240), epochs=1, accum=2, finetune=False)\n",
    "report_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bba1f4",
   "metadata": {},
   "source": [
    "Here's `vit_large`. This one is very close to going over the 16280MiB we've got on Kaggle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbb9f38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train('vit_large_patch16_224', 224, epochs=1, accum=2, finetune=False)\n",
    "report_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ec997c",
   "metadata": {},
   "source": [
    "Then finally our `swinv2` and `swin` models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc92938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train('swinv2_large_window12_192_22k', 192, epochs=1, accum=2, finetune=False)\n",
    "report_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e8cefbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train('swin_large_patch4_window7_224', 224, epochs=1, accum=2, finetune=False)\n",
    "report_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a55b7f",
   "metadata": {},
   "source": [
    "## Running the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5f9c00",
   "metadata": {},
   "source": [
    "Using the previous notebook, I tried a bunch of different architectures and preprocessing approaches on small models, and picked a few which looked good. We'll using a `dict` to list our the preprocessing approaches we'll use for each architecture of interest based on that analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58260ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 640,480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8dc102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'convnext_large_in22k': {\n",
    "        (Resize(res), 224),\n",
    "        (Resize(res), (320,224)),\n",
    "    }, 'vit_large_patch16_224': {\n",
    "        (Resize(480, method='squish'), 224),\n",
    "        (Resize(res), 224),\n",
    "    }, 'swinv2_large_window12_192_22k': {\n",
    "        (Resize(480, method='squish'), 192),\n",
    "        (Resize(res), 192),\n",
    "    }, 'swin_large_patch4_window7_224': {\n",
    "        (Resize(480, method='squish'), 224),\n",
    "        (Resize(res), 224),\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83706c47",
   "metadata": {},
   "source": [
    "We'll need to switch to using the full training set of course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b418ece4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_path = path/'train_images'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4dc386",
   "metadata": {},
   "source": [
    "Now we're ready to train all these models. Remember that each is using a different training and validation set, so the results aren't directly comparable.\n",
    "\n",
    "We'll append each set of TTA predictions on the test set into a list called `tta_res`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91ed5157",
   "metadata": {},
   "outputs": [],
   "source": [
    "tta_res = []\n",
    "\n",
    "for arch,details in models.items():\n",
    "    for item,size in details:\n",
    "        print('---',arch)\n",
    "        print(size)\n",
    "        print(item.name)\n",
    "        tta_res.append(train(arch, size, item=item, accum=2)) #, epochs=1))\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bd2d9b",
   "metadata": {},
   "source": [
    "## Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d720dc3",
   "metadata": {},
   "source": [
    "Since this has taken quite a while to run, let's save the results, just in case something goes wrong!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b370e7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle('tta_res.pkl', tta_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1fcf43",
   "metadata": {},
   "source": [
    "`Learner.tta` returns predictions and targets for each rows. We just want the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8de40a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tta_prs = first(zip(*tta_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a890f4",
   "metadata": {},
   "source": [
    "Originally I just used the above predictions, but later I realised in my experiments on smaller models that `vit` was a bit better than everything else, so I decided to give those double the weight in my ensemble. I did that by simply adding the to the list a second time (we could also do this by using a weighted average):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3093b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tta_prs += tta_prs[2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383ef283",
   "metadata": {},
   "source": [
    "An *ensemble* simply refers to a model which is itself the result of combining a number of other models. The simplest way to do ensembling is to take the average of the predictions of each model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64d79d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_pr = torch.stack(tta_prs).mean(0)\n",
    "avg_pr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a34e9c",
   "metadata": {},
   "source": [
    "That's all that's needed to create an ensemble! Finally, we copy the steps we used in the last notebook to create a submission file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d71eab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = ImageDataLoaders.from_folder(trn_path, valid_pct=0.2, item_tfms=Resize(480, method='squish'),\n",
    "    batch_tfms=aug_transforms(size=224, min_scale=0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d8bad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = avg_pr.argmax(dim=1)\n",
    "vocab = np.array(dls.vocab)\n",
    "ss = pd.read_csv(path/'sample_submission.csv')\n",
    "ss['label'] = vocab[idxs]\n",
    "ss.to_csv('subm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e5be6b",
   "metadata": {},
   "source": [
    "Now we can submit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e244be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not iskaggle:\n",
    "    from kaggle import api\n",
    "    api.competition_submit_cli('subm.csv', 'part 3 v2', comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acaf9aa",
   "metadata": {},
   "source": [
    "That's it -- at the time of creating this analysis, that got easily to the top of the leaderboard! Here are the four submissions I entered, each of which was better than the last, and each of which was ranked #1:\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/346999/174503966-65005151-8f28-4f8b-b3c3-212cf74014f1.png\" width=\"400\">\n",
    "\n",
    "*Edit: Actually the one that got to the top of the leaderboard timed out when I ran it on Kaggle Notebooks, so I had to remove two of the runs from the ensemble. There's only a very small difference in accuracy however.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8f6ced",
   "metadata": {},
   "source": [
    "Going from bottom to top, here's what each one was:\n",
    "\n",
    "1. `convnext_small` trained for 12 epochs, with TTA\n",
    "1. `convnext_large` trained the same way\n",
    "1. The ensemble in this notebook, with `vit` models not over-weighted\n",
    "1. The ensemble in this notebook, with `vit` models over-weighted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ed54c9",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a4838e",
   "metadata": {},
   "source": [
    "The key takeaway I hope to get across from this series so far is that you can get great results in image recognition using very little code and a very standardised approach, and that with a rigorous process you can improve in significant steps. Our training function, including data processing and TTA, is just half a dozen lines of code, plus another 7 lines of code to ensemble the models and create a submission file!\n",
    "\n",
    "If you found this notebook useful, please remember to click the little up-arrow at the top to upvote it, since I like to know when people have found my work useful, and it helps others find it too. If you have any questions or comments, please pop them below -- I read every comment I receive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5b966c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel version 6 successfully pushed.  Please check progress at https://www.kaggle.com/code/jhoward/scaling-up-road-to-the-top-part-3\n"
     ]
    }
   ],
   "source": [
    "# This is what I use to push my notebook from my home PC to Kaggle\n",
    "\n",
    "if not iskaggle:\n",
    "    push_notebook('jhoward', 'scaling-up-road-to-the-top-part-3',\n",
    "                  title='Scaling Up: Road to the Top, Part 3',\n",
    "                  file='10-scaling-up-road-to-the-top-part-3.ipynb',\n",
    "                  competition=comp, private=False, gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef58b48e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
